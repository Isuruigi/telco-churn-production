{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telco Customer Churn: Comprehensive Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a deep dive into model evaluation, focusing on metrics and techniques that are crucial for imbalanced classification problems like churn prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport sys\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport yaml\n\n# Add src directory to path\nsys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n\n# Data and Preprocessing\nfrom src.data_loader import TelcoDataLoader\nfrom src.preprocessor import DataPreprocessor\nfrom sklearn.model_selection import train_test_split\n\n# Models\nfrom src.base_model import LogisticRegressionModel\nfrom src.ensemble_models import RandomForestChurnModel\n\n# Evaluation\nfrom src.model_evaluator import ModelEvaluator\nfrom src.business_evaluator import BusinessEvaluator\nfrom sklearn.metrics import precision_recall_curve, auc\n\n# Load config\nwith open('../config/config.yaml', 'r') as f:\n    config = yaml.safe_load(f)\n\n# Load and preprocess data\nloader = TelcoDataLoader()\ndf = loader.load_raw_data()\ndf_processed = DataPreprocessor.preprocess_data(df.copy())\n\n# Create features and target\nX = df_processed.drop(config['target'], axis=1)\ny = df_processed[config['target']].apply(lambda x: 1 if x == 'Yes' else 0)\n\n# Create and apply preprocessing pipeline\npreprocessor = DataPreprocessor().create_preprocessing_pipeline()\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=config['training']['random_state'], stratify=y)\nX_train_transformed = preprocessor.fit_transform(X_train)\nX_test_transformed = preprocessor.transform(X_test)\n\n# Train models\nlr = LogisticRegressionModel(random_state=config['training']['random_state'])\nlr.train(X_train_transformed, y_train)\nrf = RandomForestChurnModel(random_state=config['training']['random_state'])\nrf.train(X_train_transformed, y_train)\n\nmodels_dict = {'Logistic Regression': lr.model, 'Random Forest': rf.model}"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Standard Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = ModelEvaluator(models_dict, X_test_transformed, y_test)\n",
    "comparison_df = evaluator.compare_multiple_models()\n",
    "print(\"--- Model Comparison (Standard Metrics) ---\")\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While accuracy might look good, it can be misleading in imbalanced datasets. ROC AUC is a better metric, but let's dive deeper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The plots are saved to the reports/figures/visualization directory\n",
    "evaluator.create_evaluation_plots()\n",
    "print('Confusion matrices and ROC curves have been saved to the reports/figures/visualization directory.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Precision-Recall Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision-Recall curves are often more informative than ROC curves for imbalanced datasets, as they focus on the performance of the positive (minority) class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for name, model in models_dict.items():\n",
    "    y_pred_proba = model.predict_proba(X_test_transformed)[:, 1]\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    plt.plot(recall, precision, label=f'{name} (PR AUC = {pr_auc:.2f})')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curves')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cost-Sensitive Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the imblearn classification report which provides metrics like geometric mean\n",
    "evaluator.evaluate_imbalanced_classification('Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Business Impact Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Business Assumptions ---\n",
    "AVG_MONTHLY_REVENUE = 70.0\n",
    "AVG_CUSTOMER_LIFESPAN_MONTHS = 24\n",
    "CUSTOMER_ACQUISITION_COST = 300.0\n",
    "RETENTION_CAMPAIGN_COST_PER_CUSTOMER = 50.0\n",
    "CAMPAIGN_SUCCESS_RATE = 0.4 # Assume our campaign can convince 40% of targeted churners to stay\n",
    "\n",
    "business_eval = BusinessEvaluator(\n",
    "    avg_monthly_revenue=AVG_MONTHLY_REVENUE,\n",
    "    avg_customer_lifespan_months=AVG_CUSTOMER_LIFESPAN_MONTHS,\n",
    "    customer_acquisition_cost=CUSTOMER_ACQUISITION_COST,\n",
    "    retention_campaign_cost_per_customer=RETENTION_CAMPAIGN_COST_PER_CUSTOMER\n",
    ")\n",
    "\n",
    "# Generate report for the Random Forest model\n",
    "y_pred_rf = rf.predict(X_test_transformed)\n",
    "business_eval.generate_business_impact_report(y_test, y_pred_rf, campaign_success_rate=CAMPAIGN_SUCCESS_RATE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
